{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo Evaluating\n",
    "\n",
    "Here you can evaluate and make inferences with the yolass model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import init_notebook, benchmarking, predictions\n",
    "%aimport datasets, utils.predictions, utils.benchmarking,utils.data_cleaning\n",
    "from utils.predictions import * \n",
    "\n",
    "import sahi\n",
    "from sahi import AutoDetectionModel\n",
    "import fiftyone as fo\n",
    "import torch\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "HOME = Path(os.getcwd()).parents[0]\n",
    "HOME\n",
    "\n",
    "print(\"torch available :\",torch.cuda.is_available())\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"yolass_aug_26ep\"\n",
    "\n",
    "yolo_detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type=\"yolov8\",    # Model type (base model is yolov8 also for yolov10)\n",
    "    model_path=f\"../outputs/yolo/{model_name}.pt\",    # Path to the model weights\n",
    "    confidence_threshold=0.1,   # Confidence threshold\n",
    "    # The higher the confidence threshold, the more precise they are (but we do a filtering later)\n",
    "    device=\"cuda:0\",  # to use the GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation of the dataset\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    data_path=HOME/\"data/coco_datasets/Cocass_aug/images\",  # path to the dataset\n",
    "    labels_path=HOME/\"data/coco_datasets/Cocass_aug/fraw_detailed_val.json\",   # path to the labels/annotations file\n",
    "    dataset_type=fo.types.COCODetectionDataset, # the type of dataset to import\n",
    ")\n",
    "dataset\n",
    "\n",
    "# the annotations are imported as \"detections\" but we want to rename them as \"annotations\" to avoid confusion\n",
    "dataset.rename_sample_field(\"detections\", \"annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To inspet the dataset on an external app\n",
    "session = fo.launch_app(dataset, auto=False)\n",
    "session.open_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the the dataset imported is made of crops (if not skip this kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs={\"slice_height\":1280, \"slice_width\":1280, \"overlap_height_ratio\":0.9, \"overlap_width_ratio\":0.9}\n",
    "for sample in dataset.iter_samples(progress=True, autosave=True):\n",
    "    yolo_results=fo_predict_simple(yolo_detection_model,sample, \n",
    "        label_field=\"yolo_predictions\", \n",
    "        kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset is only a full page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.predictions import fo_predict_with_slicing\n",
    "kwargs={\"slice_height\":1280, \"slice_width\":1280, \"overlap_height_ratio\":0.9, \"overlap_width_ratio\":0.9}\n",
    "# We use Sliced Aided Hyper Inference to predict on the dataset\n",
    "for sample in dataset.iter_samples(progress=True, autosave=True):\n",
    "    yolo_results=fo_predict_with_slicing(yolo_detection_model,sample, \n",
    "        label_field=\"yolo_predictions\", \n",
    "        slice_height=640, slice_width=640, overlap_height_ratio=0.8, overlap_width_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part as been added to export the results in COCO format in json to filter them and return them on fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cleaning import fiftyone_extraction_remapping,filter_annotations\n",
    "import fiftyone.utils.coco as fouc\n",
    "import json\n",
    "\n",
    "# YOLO predictions filtering\n",
    "# ------------------------\n",
    "# Export the dataset to a JSON file\n",
    "gt_json = HOME/\"data/coco_datasets/Cocass_aug/fraw_detailed_val.json\"\n",
    "#gt_json = HOME/\"data/coco_datasets/tests/Cassini_009_LoC/f009_detailed_updated.json\"\n",
    "dataset.export(\n",
    "    export_dir=\"results/jsons/val/yolo_predictions\",\n",
    "    data_path=HOME/\"data/coco_datasets/Cocass_aug/images\",\n",
    "    dataset_type=fo.types.COCODetectionDataset,  # You can choose other formats as well\n",
    "    label_field=\"yolo_predictions\",\n",
    "    classes=dataset.get_classes('annotations'),\n",
    "    export_media=False  # Set to True if you want to export media files as well\n",
    ")\n",
    "fiftyone_extraction_remapping(HOME/\"notebooks/results/jsons/val/yolo_predictions/labels.json\",\n",
    "                              gt_json,inplace=True)\n",
    "filter_annotations(json_file_path=HOME/\"notebooks/results/jsons/val/yolo_predictions/labels.json\",conf_threshold=0.5,\n",
    "                    height_width_ratio= 0.3,\n",
    "                    second_height_width_ratio=3,\n",
    "                    iou_threshold= 0.8,inside_threshold=0.2,inplace=False,keep_annotations=True,class_agnostic=False,\n",
    "                    keep_abbey=True)\n",
    "fouc.add_coco_labels(\n",
    "    dataset,\n",
    "    \"yolo_predictions_filtered\",\n",
    "    (HOME/\"notebooks/results/jsons/val/yolo_predictions/filtered_labels.json\").as_posix(),\n",
    "    classes=dataset.get_classes('annotations'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the model (we use the base fiftyone function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_results = dataset.evaluate_detections(\n",
    "    \"yolo_predictions_filtered\",\n",
    "    gt_field=\"annotations\",\n",
    "    eval_key=\"yolo_eval\",\n",
    "    compute_mAP=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" YOLO evaluation on test dataset :\")\n",
    "yolo_results.print_report(classes=dataset.get_classes('annotations'))\n",
    "print(\"YOLO mAP :\",yolo_results.mAP())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes\n",
    "This part can be used to export dataframes from the results (in csv, json or xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.benchmarking import fo_result2pd\n",
    "yolo_df_9 = fo_result2pd(yolo_results,file_path=\"results/val/filtered_yolo_results.json\",save_json=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrices\n",
    "Those function takes as inputs the json exported from fiftyone. You may also use a built-in function from fiftyone but i find it hard to read and difficult to export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I do not like the confusion matrix from fiftyone, I will use my own\n",
    "from utils.benchmarking import fo_plot_confusion_matrix\n",
    "plot = fo_plot_confusion_matrix(yolo_results,normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.benchmarking import  build_confusion_matrix, plot_confusion_matrix\n",
    "# Build the confusion matrix\n",
    "confusion_matrix,categories = build_confusion_matrix(gt_json,pred_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_confusion_matrix(confusion_matrix,categories,normalize=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
