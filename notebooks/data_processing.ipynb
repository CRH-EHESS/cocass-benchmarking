{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "\n",
    "This notebook allows you to make transformations and augmentation of your dataset. Indeed, some models like YOLO take in YOLO formatted datasets, while the majority of detection models prefer COCO format annotated datasets.\n",
    "<br></br>\n",
    "Here is how this notebook works :\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"images/Data_transform_graph.png\" alt=\"Data transformation graph\" title=\"Data transformation graph\">\n",
    "</div>\n",
    "\n",
    "The different formats are as follows:\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>COCO</th>\n",
    "    <th>YOLOv5</th>\n",
    "    <th>YOLOv8</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td>\n",
    "      <pre>\n",
    "COCO/\n",
    "├── data/\n",
    "│   └── images/\n",
    "└── └── annotations.json\n",
    "  </pre>\n",
    "</td>\n",
    "    <td>\n",
    "      <pre>\n",
    "YOLOv5/\n",
    "├── data/\n",
    "│   ├── images/\n",
    "│   │   ├── train/\n",
    "│   │   └── val/\n",
    "│   ├── labels/\n",
    "│   │   ├── train/\n",
    "│   │   └── val/\n",
    "└── └── data.yaml\n",
    "  </pre>\n",
    "</td>\n",
    "<td>\n",
    "  <pre>\n",
    "YOLOv8/\n",
    "├── data/\n",
    "│   ├── train/\n",
    "│   │   ├── images/\n",
    "│   │   └── labels/\n",
    "│   ├── valid/\n",
    "│   │   ├── images/\n",
    "│   │   └── labels/\n",
    "└── └── data.yaml\n",
    "  </pre>\n",
    "</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Note thate here you will also be able to merge multiple different COOC datasets into one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/Geomatique/Documents/map-symbols-detection-in-historical-maps/notebooks/Sutty_pipeline')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import init_notebook\n",
    "%aimport datasets, datasets.cocodetr, datasets.data_transform\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "HOME = Path(os.getcwd()).parents[0]\n",
    "HOME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coco to Coco splitted (train-val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_file = (HOME).as_posix()+\"/data/coco_datasets/Cocass/fraw_detailed.json\"\n",
    "images_folder =(HOME).as_posix()+\"/data/coco_datasets/Cocass/images\"\n",
    "\n",
    "from datasets.cocodetr import create_coco_pth_datasets\n",
    "\n",
    "# this function split a coco-like dataset into train and val datasets\n",
    "# It extracts the annotations files but those files refers to the same image folder, just not the same images\n",
    "create_coco_pth_datasets(annotations_file, images_folder,\n",
    "                        split_only=True,                    \n",
    "                        train_ann_name=\"fraw_detailed_train.json\",\n",
    "                        val_ann_name=\"fraw_detailed_val.json\",\n",
    "                        test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coco to Yolo format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function helps you extract from a COCO dataset (full) a YOLO formatted dataset. If your COCO dataset is splitted, call this function without split on each annotation file representing your split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Geomatique\\Documents\\map-symbols-detection-in-historical-maps\\ehess_env\\Lib\\site-packages\\pylabel\\shared.py:51: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_copy = df.replace(r\"^\\s*$\", np.nan, regex=True)\n",
      "Exporting YOLO files...: 100%|██████████| 6383/6383 [00:40<00:00, 158.31it/s]\n"
     ]
    }
   ],
   "source": [
    "annotations_file = (HOME).as_posix()+\"/data/coco_datasets/Cocass_aug/ffull_detailed_train.json\"\n",
    "images_folder =(HOME).as_posix()+\"/data/coco_datasets/Cocass_aug/images\"\n",
    "\n",
    "\n",
    "output_dir = (HOME/\"data/yolo_datasets/Yolass_aug/train/\").as_posix()\n",
    "from datasets.data_transform import coco2yolo\n",
    "\n",
    "coco2yolo(annotations_file,images_folder,\n",
    "          output_dir= output_dir, # output folder\n",
    "          copy_images=True, # copy images to output folder (if not only annotations are extracted)\n",
    "          yolo_type=\"yolov8\",    # or yolov5 (only yolov8 is supported as of now)\n",
    "          split=False,   # split the dataset into train and val (if False you get YOLO Dataset (full))\n",
    "          split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data.yaml files in Yolass_aug into one data.yaml file.\n"
     ]
    }
   ],
   "source": [
    "#If split = False you may use\n",
    "output_dir = (HOME/\"data/yolo_datasets/Yolass_aug\").as_posix()\n",
    "from datasets.data_transform import merge_yaml\n",
    "merge_yaml(output_dir,train_name=\"train\",valid_name=\"val\",augment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOv5 $\\leftrightarrow$ YOLOv8\n",
    "This part allows you to make the conversion between Yolov5 formatted datasets folders and Yolov8 formatted folders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOLOv5 $\\rightarrow$ YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov5_folder_path = \"<your_yolov5_folder_path>\"\n",
    "yolov8_output_folder = \"<your_yolov8_folder_path>\"\n",
    "from datasets.data_transform import convert_yolov5_to_yolov8\n",
    "\n",
    "convert_yolov5_to_yolov8(yolov5_folder_path, yolov8_output_folder)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOLOv5 $\\leftarrow$ YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov8_folder_path = (HOME/\"data/yolo_datasets/Yolass_aug\").as_posix() #\"<your_yolov8_folder_path>\"\n",
    "yolov5_output_folder = (HOME/\"data/yolo_datasets/Yolass_augv5\").as_posix()#\"<your_yolov5_folder_path>\"\n",
    "from datasets.data_transform import convert_yolov8_to_yolov5\n",
    "\n",
    "convert_yolov8_to_yolov5(yolov8_folder_path, yolov5_output_folder)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA augmentation\n",
    "Here we only augment COCO Datasets\n",
    "\n",
    "\n",
    "The augmentation requires a 'train_annotations.json' file as we need to only augment the train dataset. Thus, you need to split your COCO dataset beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.data_transform import albu_coco_augmentation\n",
    "import os\n",
    "# annotations_file = (HOME).as_posix()+\"/data/coco_datasets/Cocass/ffull_detailed_train.json\",\n",
    "# images_folder = (HOME).as_posix()+\"/data/coco_datasets/Cocass/images\"\n",
    "annotations_file = os.path.join(HOME,\"data/coco_datasets/Cocass/ffull_detailed_train.json\")#\"/data/coco_datasets/Cocass/ffull_detailed_train.json\",\n",
    "images_folder = os.path.join(HOME,\"data/coco_datasets/Cocass/images\")\n",
    "\n",
    "output_dir = (HOME).as_posix()+\"/data/coco_datasets/Cocass_aug\" #path to save the augmented dataset\n",
    "\n",
    "albu_coco_augmentation(\n",
    "    # By default the augmentation techniques are set to False\n",
    "                    annotations_file,images_folder,  \n",
    "                    output_folder=output_dir,       #path to save the augmented dataset\n",
    "                    annotations_name=\"ffull_detailed_train\" , #name of the augmented annotations file\n",
    "                    blur=True,                      #apply blur augmentation\n",
    "                    #blur_limit = 15,               #How much to blur the image (limit for the random value)\n",
    "                    grayscale = True,               #apply grayscale augmentation\n",
    "                    equalize = True,                #apply equalize augmentation\n",
    "                    dropout = True,                 #apply dropout augmentation (randomly remove pixels)\n",
    "                    # dropout_percentage = 0.15,    #percentage of pixels to remove\n",
    "                    hue_saturation = True,          #apply hue and saturation augmentation\n",
    "                    # hue_shift_limit = 10,         #How much to shift the hue (limit for the random value)\n",
    "                    # saturation_limit = 10,        #How much to change the saturation (limit for the random value)\n",
    "                    brightness = True,              #apply brightness and contrast augmentation\n",
    "                    # brightness_limit  = 0.2,      #How much to change the brightness (limit for the random value)\n",
    "                    # contrast_limit = 0.2,         #How much to change the contrast (limit for the random value)\n",
    "                    gamma = True,                   #apply gamma augmentation\n",
    "                    gamma_range  = (10, 130),     #range to apply gamma\n",
    "                    augmentation_ratio= 0.2,        #percentage of images to augment\n",
    "                    verbose=True\n",
    "                    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you want to get back the original annotations with val and train merged\n",
    "from datasets.data_transform import merge_coco_annotations\n",
    "train_annotations_file = (HOME).as_posix()+\"/data/coco_datasets/cocass_f52_synth_4000_6000_3000_1000_1280_nlabels_aug/train_detailed_nolabelsonly.json\"\n",
    "val_annotations_file = (HOME).as_posix()+\"/data/coco_datasets/cocass_f52_synth_4000_6000_3000_1000_1280_nlabels_aug/val_detailed_nolabelsonly.json\"\n",
    "images_folder = (HOME).as_posix()+\"/data/coco_datasets/cocass_f52_synth_4000_6000_3000_1000_1280_nlabels_aug/\"\n",
    "\n",
    "merge_coco_annotations([train_annotations_file, val_annotations_file], images_folder+\"detailed_nolabelsonly.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.data_transform import merge_coco_json\n",
    "merging= [(HOME).as_posix()+\"/data/coco_datasets/Cocass_aug/fraw_detailed_val.json\",\n",
    "          (HOME).as_posix()+\"/data/coco_datasets/Cocass_aug/ffull_detailed_train.json\",\n",
    "\n",
    "]\n",
    "merge_coco_json(merging, \n",
    "                       (HOME).as_posix()+\"/data/coco_datasets/Cocass_aug/ffull_detailed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.data_transform import merge_coco_json\n",
    "merging= [(HOME).as_posix()+\"/data/coco_datasets/Cocass/f006_detailed.json\",\n",
    "          (HOME).as_posix()+\"/data/coco_datasets/Cocass/f008_detailed.json\",\n",
    "          (HOME).as_posix()+\"/data/coco_datasets/Cocass/f052_detailed.json\",\n",
    "          (HOME).as_posix()+\"/data/coco_datasets/Cocass/f165_detailed.json\",\n",
    "          #(HOME).as_posix()+\"/data/coco_datasets/Cocass/fsynth_detailed.json\",\n",
    "]\n",
    "merge_coco_json(merging, \n",
    "                       (HOME).as_posix()+\"/data/coco_datasets/Cocass/fraw_detailed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.data_transform import make_ids_linear\n",
    "make_ids_linear((HOME).as_posix()+\"/data/coco_datasets/Cocass/ffull_detailed_train.json\",(HOME).as_posix()+\"/data/coco_datasets/Cocass/ffull_detailed.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehess_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
